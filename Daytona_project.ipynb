{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99SWsKazZcxZ"
      },
      "source": [
        "Install needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUsTXAaMj4It",
        "outputId": "103f6403-bacf-4680-b279-5ea8fd32e708"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.32.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2024.6.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2.2.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (3.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 24.1 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyGithub in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.3.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from PyGithub) (2.2.1)\n",
            "Requirement already satisfied: pynacl>=1.4.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from PyGithub) (1.5.0)\n",
            "Requirement already satisfied: requests>=2.14.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from PyGithub) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\mate\\appdata\\roaming\\python\\python39\\site-packages (from PyGithub) (4.12.2)\n",
            "Requirement already satisfied: Deprecated in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from PyGithub) (1.2.14)\n",
            "Requirement already satisfied: pyjwt[crypto]>=2.4.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from PyGithub) (2.8.0)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (42.0.8)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.4.0->PyGithub) (1.16.0)\n",
            "Requirement already satisfied: pycparser in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.4.0->PyGithub) (2.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.14.0->PyGithub) (2024.6.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.14.0->PyGithub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.14.0->PyGithub) (3.7)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Deprecated->PyGithub) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 24.1 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.34.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\mate\\appdata\\roaming\\python\\python39\\site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\mate\\appdata\\roaming\\python\\python39\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: certifi in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\mate\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 24.1 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.34.0)\n",
            "Collecting openai\n",
            "  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\mate\\appdata\\roaming\\python\\python39\\site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\mate\\appdata\\roaming\\python\\python39\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: certifi in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\mate\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.34.0\n",
            "    Uninstalling openai-1.34.0:\n",
            "      Successfully uninstalled openai-1.34.0\n",
            "Successfully installed openai-1.35.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The script openai.exe is installed in 'c:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "WARNING: You are using pip version 21.2.3; however, version 24.1 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The script dotenv.exe is installed in 'c:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "WARNING: You are using pip version 21.2.3; however, version 24.1 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "%pip install requests\n",
        "%pip install PyGithub\n",
        "%pip install openai\n",
        "%pip install --upgrade openai\n",
        "%pip install python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9EtvGvDj16g"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "ztCe4NgXj6On"
      },
      "outputs": [],
      "source": [
        "from github import Github\n",
        "from openai import OpenAI  \n",
        "import json\n",
        "import requests\n",
        "import re\n",
        "from dotenv import load_dotenv\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvvDeh4pjxXJ"
      },
      "source": [
        "Function to check if input is already a GitHub repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "XSMxuFSCbBBJ"
      },
      "outputs": [],
      "source": [
        "def is_github_repo_link(env):\n",
        "    return env.startswith(\"https://github.com/\") or env.startswith(\"http://github.com/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXke2spCavGG"
      },
      "source": [
        "Prompt for user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59Z2rh5mZfRE",
        "outputId": "7ef22307-13fb-432a-eef6-d59393efe10f"
      },
      "outputs": [],
      "source": [
        "prompt = input(\"Enter a name of the environment or link to GitHub repo: \")\n",
        "flag = True\n",
        "if is_github_repo_link(prompt) == False:\n",
        "   flag = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0EL_NkliqeI"
      },
      "source": [
        "Function for searching GitHub repositories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "7w02ek88i7SN"
      },
      "outputs": [],
      "source": [
        "def retrieve_files(repo_urls):\n",
        "    file_names = ['README.md', 'install.md', 'package.json']\n",
        "    branches = ['main', 'master', 'develop']\n",
        "    additional_paths = ['', 'docs/', 'src/']\n",
        "    files_content = {file_name: [] for file_name in file_names}\n",
        "\n",
        "    for url in repo_urls:\n",
        "        if url.endswith('.git'):\n",
        "            trimmed_url = url[:-4]\n",
        "        else:\n",
        "            trimmed_url = url\n",
        "\n",
        "        file_found = {file_name: False for file_name in file_names}\n",
        "\n",
        "        for branch in branches:\n",
        "            for additional_path in additional_paths:\n",
        "                for file_name in file_names:\n",
        "                    if not file_found[file_name]:\n",
        "                        file_url = f\"{trimmed_url.rstrip('/')}/raw/{branch}/{additional_path}{file_name}\"\n",
        "                        try:\n",
        "                            response = requests.get(file_url)\n",
        "                            if response.status_code == 200:\n",
        "                                files_content[file_name].append(response.text)\n",
        "                                file_found[file_name] = True\n",
        "                                print(f\"Successfully retrieved {file_name} from {file_url}\")\n",
        "                            else:\n",
        "                                print(f\"Failed to retrieve {file_name} for {url} on branch {branch} at path {additional_path}. Status code: {response.status_code}\")\n",
        "                        except requests.exceptions.RequestException as e:\n",
        "                            print(f\"Error while trying to get {file_name} for {url} on branch {branch} at path {additional_path}: {e}\")\n",
        "\n",
        "    return files_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqNtexJlrsAC"
      },
      "source": [
        "OpenAI API for getting repositories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "6JLbTX8SrvO0"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "client = OpenAI(\n",
        "    api_key = os.getenv(\"AZURE_OPENAI_KEY\"),\n",
        "    base_url=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        ")\n",
        "def generate_github_repos(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    system_prompt = \"You are an AI assistant that suggests relevant GitHub repositories based on a project description.\"\n",
        "    user_prompt = f\"Suggest GitHub repositories for a project that involves the following technologies: {prompt}. Provide only the URLs of the repositories.\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    suggested_repos = response.choices[0].message.content.strip()\n",
        "    repo_urls = re.findall(r'(https?://github\\.com/[^\\s]+)', suggested_repos)\n",
        "\n",
        "    return repo_urls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OnKaxF7X4fe"
      },
      "source": [
        "Analyze and pre-process the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rw0PzSofrwpL"
      },
      "outputs": [],
      "source": [
        "def parse_readme(content):\n",
        "    sections = {}\n",
        "    current_section = None\n",
        "    lines = content.split('\\n')\n",
        "\n",
        "    for line in lines:\n",
        "        header_match = re.match(r'^(#+)\\s+(.*)', line)\n",
        "        if header_match:\n",
        "            level = len(header_match.group(1))\n",
        "            section_name = header_match.group(2).strip()\n",
        "            current_section = section_name\n",
        "            sections[current_section] = []\n",
        "        elif current_section:\n",
        "            sections[current_section].append(line)\n",
        "\n",
        "    for section in sections:\n",
        "        sections[section] = \"\\n\".join(sections[section])\n",
        "\n",
        "    return sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bbzs3gu2tHcG"
      },
      "outputs": [],
      "source": [
        "def parse_package_json(content):\n",
        "    try:\n",
        "        package_data = json.loads(content)\n",
        "        return {\n",
        "            \"dependencies\": package_data.get(\"dependencies\", {}),\n",
        "            \"devDependencies\": package_data.get(\"devDependencies\", {}),\n",
        "            \"scripts\": package_data.get(\"scripts\", {})\n",
        "        }\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error parsing package.json: {e}\")\n",
        "        return {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qvL53TGvtLjH"
      },
      "outputs": [],
      "source": [
        "def collect_context(files_content):\n",
        "    context = {}\n",
        "\n",
        "    for file_name, contents in files_content.items():\n",
        "        if file_name == 'README.md':\n",
        "            for content in contents:\n",
        "                context[file_name] = parse_readme(content)\n",
        "        elif file_name == 'package.json':\n",
        "            for content in contents:\n",
        "                context[file_name] = parse_package_json(content)\n",
        "\n",
        "    return context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b7IEDS64vbc"
      },
      "source": [
        "Validation of output, this is just for us to see how is data being processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c61ngjPXyyeD",
        "outputId": "b6a3702a-e500-46f8-8a9c-b02284d50094"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'context' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#context is underlined beacuse it's defined below, in main code section, but that doesn't matter since this is jupyter notebook\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpackage.json\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcontext\u001b[49m:\n\u001b[0;32m      3\u001b[0m     package_info \u001b[38;5;241m=\u001b[39m context[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpackage.json\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m     dependencies \u001b[38;5;241m=\u001b[39m package_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdependencies\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n",
            "\u001b[1;31mNameError\u001b[0m: name 'context' is not defined"
          ]
        }
      ],
      "source": [
        "#context is underlined beacuse it's defined below, in main code section, but that doesn't matter since this is jupyter notebook\n",
        "if 'package.json' in context:\n",
        "    package_info = context['package.json']\n",
        "    dependencies = package_info.get('dependencies', {})\n",
        "    dev_dependencies = package_info.get('devDependencies', {})\n",
        "    scripts = package_info.get('scripts', {})\n",
        "\n",
        "    print(\"Dependencies:\", dependencies)\n",
        "    print(\"Dev Dependencies:\", dev_dependencies)\n",
        "    print(\"Scripts:\", scripts)\n",
        "else:\n",
        "    print(\"No 'package.json' found in context.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c4jHad3y__n",
        "outputId": "4979bfe1-4076-4787-b748-d060c648924f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'context' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#context is underlined beacuse it's defined below, in main code section, but that doesn't matter since this is jupyter notebook\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREADME.md\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcontext\u001b[49m:\n\u001b[0;32m      3\u001b[0m     readme_info \u001b[38;5;241m=\u001b[39m context[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREADME.md\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m section_name, section_content \u001b[38;5;129;01min\u001b[39;00m readme_info\u001b[38;5;241m.\u001b[39mitems():\n",
            "\u001b[1;31mNameError\u001b[0m: name 'context' is not defined"
          ]
        }
      ],
      "source": [
        "#context is underlined beacuse it's defined below, in main code section, but that doesn't matter since this is jupyter notebook\n",
        "if 'README.md' in context:\n",
        "    readme_info = context['README.md']\n",
        "\n",
        "    for section_name, section_content in readme_info.items():\n",
        "        print(f\"Section: {section_name}\")\n",
        "        print(section_content)\n",
        "        print()\n",
        "else:\n",
        "    print(\"No 'README.md' found in context.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8sQjtEG1WSh"
      },
      "source": [
        "Generate JSON file for Dev Container with OpenAI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "R15es83F1cLG"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "client = OpenAI(\n",
        "    api_key = os.getenv(\"AZURE_OPENAI_KEY\"),\n",
        "    base_url=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        ")\n",
        "def generate_dev_container_json(context, model=\"gpt-3.5-turbo\"):\n",
        "    system_prompt = \"You are an AI assistant that creates JSON file for dev container.\\n\\n\"\n",
        "    user_prompt = f\"Generate JSON configuration for dev container based on the context provided: {context}\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(\"Raw API Response:\")\n",
        "    print(response)\n",
        "\n",
        "    if 'data' in response:\n",
        "        for message in response['data']:\n",
        "            if message['role'] == 'assistant':\n",
        "                generated_json = message['content']\n",
        "                try:\n",
        "                    parsed_json = json.loads(generated_json)\n",
        "                    print(\"Generated Dev Container JSON Configuration:\")\n",
        "                    print(json.dumps(parsed_json, indent=4))\n",
        "                    return parsed_json\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Error decoding JSON: {e}\")\n",
        "                    return None\n",
        "            else:\n",
        "                print(f\"Role '{message['role']}' not recognized.\")\n",
        "                return None\n",
        "    else:\n",
        "        print(\"No 'data' key found in API response.\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TUo797zZ2tN"
      },
      "source": [
        "Main code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJf_6snmZ56b",
        "outputId": "58622757-38fc-42b2-ab41-201b1e7fe854"
      },
      "outputs": [
        {
          "ename": "NotFoundError",
          "evalue": "Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[90], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flag \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m   repos\u001b[38;5;241m=\u001b[39m\u001b[43mgenerate_github_repos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;28mprint\u001b[39m(repos)\n\u001b[0;32m      4\u001b[0m   files\u001b[38;5;241m=\u001b[39mretrieve_files(repos)\n",
            "Cell \u001b[1;32mIn[88], line 10\u001b[0m, in \u001b[0;36mgenerate_github_repos\u001b[1;34m(prompt, model)\u001b[0m\n\u001b[0;32m      7\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an AI assistant that suggests relevant GitHub repositories based on a project description.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m user_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuggest GitHub repositories for a project that involves the following technologies: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Provide only the URLs of the repositories.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m suggested_repos \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     19\u001b[0m repo_urls \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(https?://github\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.com/[^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]+)\u001b[39m\u001b[38;5;124m'\u001b[39m, suggested_repos)\n",
            "File \u001b[1;32mc:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\resources\\chat\\completions.py:606\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    605\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1239\u001b[0m     )\n\u001b[1;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[1;32mc:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:1020\u001b[0m, in \u001b[0;36m_request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1014\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1016\u001b[0m         options,\n\u001b[0;32m   1017\u001b[0m         cast_to,\n\u001b[0;32m   1018\u001b[0m         retries,\n\u001b[0;32m   1019\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m-> 1020\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1021\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1022\u001b[0m     )\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
            "\u001b[1;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}"
          ]
        }
      ],
      "source": [
        "if flag == False:\n",
        "  repos=generate_github_repos(prompt)\n",
        "  print(repos)\n",
        "  files=retrieve_files(repos)\n",
        "else:\n",
        "  repo=[prompt]\n",
        "  files=retrieve_files(repo)\n",
        "context = collect_context(files)\n",
        "generate_dev_container_json(context)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
