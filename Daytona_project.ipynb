{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99SWsKazZcxZ"
      },
      "source": [
        "Install needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUsTXAaMj4It",
        "outputId": "103f6403-bacf-4680-b279-5ea8fd32e708"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.32.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2024.6.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2.2.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 24.1 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyGithub in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.3.0)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\mate\\appdata\\roaming\\python\\python39\\site-packages (from PyGithub) (4.12.2)\n",
            "Requirement already satisfied: Deprecated in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from PyGithub) (1.2.14)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from PyGithub) (2.2.1)\n",
            "Requirement already satisfied: requests>=2.14.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from PyGithub) (2.32.3)\n",
            "Requirement already satisfied: pynacl>=1.4.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from PyGithub) (1.5.0)\n",
            "Requirement already satisfied: pyjwt[crypto]>=2.4.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from PyGithub) (2.8.0)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (42.0.8)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.4.0->PyGithub) (1.16.0)\n",
            "Requirement already satisfied: pycparser in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.4.0->PyGithub) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.14.0->PyGithub) (3.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.14.0->PyGithub) (2024.6.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.14.0->PyGithub) (3.7)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Deprecated->PyGithub) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 24.1 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.35.4)\n",
            "Requirement already satisfied: sniffio in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\mate\\appdata\\roaming\\python\\python39\\site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\mate\\appdata\\roaming\\python\\python39\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\mate\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 24.1 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.35.4)\n",
            "Collecting openai\n",
            "  Downloading openai-1.35.5-py3-none-any.whl (327 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\mate\\appdata\\roaming\\python\\python39\\site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\mate\\appdata\\roaming\\python\\python39\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: certifi in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\mate\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.35.4\n",
            "    Uninstalling openai-1.35.4:\n",
            "      Successfully uninstalled openai-1.35.4\n",
            "Successfully installed openai-1.35.5\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The script openai.exe is installed in 'c:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "WARNING: You are using pip version 21.2.3; however, version 24.1 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in c:\\users\\mate\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.3; however, version 24.1 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "%pip install requests\n",
        "%pip install PyGithub\n",
        "%pip install openai\n",
        "%pip install --upgrade openai\n",
        "%pip install python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9EtvGvDj16g"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ztCe4NgXj6On"
      },
      "outputs": [],
      "source": [
        "from github import Github\n",
        "from openai import OpenAI,AzureOpenAI\n",
        "import json\n",
        "import requests\n",
        "import re\n",
        "from dotenv import load_dotenv\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvvDeh4pjxXJ"
      },
      "source": [
        "Function to check if input is already a GitHub repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XSMxuFSCbBBJ"
      },
      "outputs": [],
      "source": [
        "def is_github_repo_link(env):\n",
        "    return env.startswith(\"https://github.com/\") or env.startswith(\"http://github.com/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXke2spCavGG"
      },
      "source": [
        "Prompt for user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59Z2rh5mZfRE",
        "outputId": "7ef22307-13fb-432a-eef6-d59393efe10f"
      },
      "outputs": [],
      "source": [
        "prompt = input(\"Enter a name of the environment or link to GitHub repo: \")\n",
        "flag = True\n",
        "if is_github_repo_link(prompt) == False:\n",
        "   flag = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0EL_NkliqeI"
      },
      "source": [
        "Function for searching GitHub repositories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "7w02ek88i7SN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully retrieved README.md from https://github.com/angular/angular/raw/main/.circleci/README.md\n",
            "Successfully retrieved README.md from https://github.com/angular/angular/raw/main/.devcontainer/README.md\n",
            "Successfully retrieved README.md from https://github.com/angular/angular/raw/main/.vscode/README.md\n",
            "Successfully retrieved README.md from https://github.com/angular/angular/raw/main/.yarn/README.md\n",
            "Successfully retrieved README.md from https://github.com/angular/angular/raw/main/adev/README.md\n",
            "Successfully retrieved README.md from https://github.com/angular/angular/raw/main/devtools/README.md\n",
            "Successfully retrieved README.md from https://github.com/angular/angular/raw/main/goldens/README.md\n",
            "Successfully retrieved README.md from https://github.com/angular/angular/raw/main/integration/README.md\n",
            "Successfully retrieved README.md from https://github.com/angular/angular/raw/main/packages/README.md\n",
            "Successfully retrieved README.md from https://github.com/angular/angular/raw/main/third_party/README.md\n",
            "Failed to retrieve directory contents from https://api.github.com/repos/angular/angular/contents/. Status code: 404\n",
            "Failed to retrieve directory contents from https://api.github.com/repos/angular/angular/contents/. Status code: 404\n",
            "{'README.md': ['# Encryption\\n\\nBased on https://github.com/circleci/encrypted-files\\n\\nIn the CircleCI web UI, we have a secret variable called `KEY`\\nhttps://circleci.com/gh/angular/angular/edit#env-vars\\nwhich is only exposed to non-fork builds\\n(see \"Pass secrets to builds from forked pull requests\" under\\nhttps://circleci.com/gh/angular/angular/edit#advanced-settings)\\n\\nWe use this as a symmetric AES encryption key to encrypt tokens like\\na GitHub token that enables publishing snapshots.\\n\\nTo create the github_token file, we take this approach:\\n- Find the angular-builds:token in the internal pw database\\n- Go inside the CircleCI default docker image so you use the same version of openssl as we will at runtime: `docker run --rm -it circleci/node:10.12`\\n- echo \"https://[token]:@github.com\" > credentials\\n- openssl aes-256-cbc -e -in credentials -out .circleci/github_token -k $KEY\\n- If needed, base64-encode the result so you can copy-paste it out of docker: `base64 github_token`\\n', \"# VSCode Remote Development - Developing inside a Container\\n\\nThis folder contains configuration files that can be used to opt into working on this repository in a [Docker container](https://www.docker.com/resources/what-container) via [VSCode](https://code.visualstudio.com/)'s Remote Development feature (see below).\\n\\nInfo on remote development and developing inside a container with VSCode:\\n- [VSCode: Remote Development](https://code.visualstudio.com/docs/remote/remote-overview)\\n- [VSCode: Developing inside a Container](https://code.visualstudio.com/docs/remote/containers)\\n- [VSCode: Remote Development FAQ](https://code.visualstudio.com/docs/remote/faq)\\n\\n\\n## Usage\\n\\n_Prerequisite: [Install Docker](https://docs.docker.com/install) on your local environment._\\n\\nTo get started, read and follow the instructions in [Developing inside a Container](https://code.visualstudio.com/docs/remote/containers). The [.devcontainer/](.) directory contains pre-configured `devcontainer.json` and `Dockerfile` files, which you can use to set up remote development with a docker container.\\n\\nIn a nutshell, you need to:\\n- Install the [Remote - Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) extension.\\n- Copy [recommended-Dockerfile](./recommended-Dockerfile) to `Dockerfile` (and optionally tweak to suit your needs).\\n- Copy [recommended-devcontainer.json](./recommended-devcontainer.json) to `devcontainer.json` (and optionally tweak to suit your needs).\\n- Open VSCode and bring up the [Command Palette](https://code.visualstudio.com/docs/getstarted/userinterface#_command-palette).\\n- Type `Remote-Containers: Open Folder in Container` and choose your local clone of [angular/angular](https://github.com/angular/angular).\\n\\nThe `.devcontainer/devcontainer.json` and `.devcontainer/Dockerfile` files are ignored by git, so you can have your own local versions. We may occasionally update the template files ([recommended-devcontainer.json](./recommended-devcontainer.json), [recommended-Dockerfile](./recommended-Dockerfile)), in which case you will need to manually update your local copies (if desired).\\n\\n\\n## Updating `recommended-devcontainer.json` and `recommended-Dockerfile`\\n\\nYou can update and commit the recommended config files (which people use as basis for their local configs), if you find that something is broken, out-of-date or can be improved.\\n\\nPlease, keep in mind that any changes you make will potentially be used by many people on different environments. Try to keep these config files cross-platform compatible and free of personal preferences.\\n\", '# VSCode Configuration\\n\\nThis folder contains opt-in [Workspace Settings](https://code.visualstudio.com/docs/getstarted/settings), [Tasks](https://code.visualstudio.com/docs/editor/tasks), [Launch Configurations](https://code.visualstudio.com/Docs/editor/debugging#_launch-configurations) and [Extension Recommendations](https://code.visualstudio.com/docs/editor/extension-gallery#_workspace-recommended-extensions) that the Angular team recommends using when working on this repository.\\n\\n## Usage\\n\\nTo use the recommended configurations follow the steps below:\\n\\n- install the recommended extensions in `.vscode/extensions.json`\\n- copy (or link) `.vscode/recommended-settings.json` to `.vscode/settings.json`\\n- copy (or link) `.vscode/recommended-launch.json` to `.vscode/launch.json`\\n- copy (or link) `.vscode/recommended-tasks.json` to `.vscode/tasks.json`\\n- restart the editor\\n\\nIf you already have your custom workspace settings, you should instead manually merge the file contents.\\n\\nThis isn\\'t an automatic process, so you will need to repeat it when settings are updated.\\n\\nTo see the recommended extensions select \"Extensions: Show Recommended Extensions\" in the [Command Palette](https://code.visualstudio.com/docs/getstarted/userinterface#_command-palette).\\n\\n## Editing `.vscode/recommended-*.json` files\\n\\nIf you wish to add extra configuration items please keep in mind any modifications you make here will be used by many users.\\n\\nTry to keep these settings/configurations to things that help facilitate the development process and avoid altering the user workflow whenever possible.\\n', \"# Yarn Vendoring\\nWe utilize Yarn's `yarn-path` configuration in a shared `.yarnrc` file to enforce\\neveryone using the same version of Yarn.  Yarn checks the `.yarnrc` file to\\ndetermine if yarn should delegate the command to a vendored version at the\\nprovided path.\\n\\n## How to update\\nTo update to the latest version of Yarn as our vendored version:\\n- Run this command\\n```sh\\nyarn policies set-version latest\\n```\\n- Remove the previous version\\n\", \"# [Angular.dev](https://www.angular.dev)\\n\\nThis site is built with Angular.\\n\\nThe content is written primarly in Markdown format located in `src/content`. For simple edits, you can directly edit the file on GitHub and generate a Pull Request.\\n\\n## Local Development\\n\\nFor local development, [yarn](https://yarnpkg.com/) is the preferred package manager. You can setup a local environment with the following commands\\n:\\n\\n```bash\\n# Clone Angular repo\\ngit clone https://github.com/angular/angular.git\\n\\n# Navigate to project directory\\ncd angular\\n\\n# Install dependencies\\nyarn\\n\\n# Build and run local dev server\\n# Note: Initial build will take some time\\nyarn docs\\n```\\n\\n## Contributing\\n\\nWant to report a bug, contribute some code, or improve the documentation? Excellent!\\n\\nRead through our [contributing guidelines](/CONTRIBUTING.md) to learn about our submission process, coding rules, and more.\\n\\nAnd if you're new, check out one of our issues labeled as <kbd>[help wanted](https://github.com/angular/angular/labels/help%20wanted)</kbd> or <kbd>[good first issue](https://github.com/angular/angular/labels/good%20first%20issue)</kbd>.\\n\\n### Code of Conduct\\n\\nHelp us keep Angular open and inclusive. Please read and follow our [Code of Conduct](CODE_OF_CONDUCT.md).\\n\", '# Angular DevTools\\n\\nAngular DevTools is a browser DevTools extension for debugging and profiling Angular applications.\\n\\n## Developing Locally\\n\\n<!-- This duplicates some general content for setting up the angular/angular repository, however it is important to\\n     have complete instructions here for Mozilla Add-On reviewers who need to be able to reproduce Angular DevTools\\n     builds and will use the same documentation. -->\\n\\n### Set up\\n\\nFollow the instructions below to set up your Angular DevTools development\\nenvironment. Note that all commands should be executed in the repository root, not\\n`devtools/`. All file paths are also relative to the repository root.\\n\\nDebian Linux, MacOS, and Windows via WSL should build successfully. Building\\nnatively on Windows without WSL is not supported at the moment.\\n\\nTo set up your development environment, first install the [correct version of Node](/.nvmrc). If you have\\n[`nvm`](https://github.com/nvm-sh/nvm) set up, this can be done with:\\n\\n```shell\\nnvm install\\n```\\n\\nSecond, install [Yarn](https://classic.yarnpkg.com/en/):\\n\\n```shell\\nnpm install -g yarn@1\\n```\\n\\nThird, install NPM dependencies:\\n\\n```shell\\nyarn --frozen-lockfile\\n```\\n\\nNow you should be ready to build the DevTools extension.\\n\\n### Dev builds\\n\\nTo run the extension in development mode run:\\n\\n```shell\\nyarn devtools:devserver\\n```\\n\\nYou can also run a standalone version of the demo app with:\\n\\n```shell\\nyarn devtools:devserver:demo-standalone\\n```\\n\\nThis would start a development server that you can access on <http://localhost:4200>. In development, Angular DevTools\\nuses a \"development shell.\" This is different from \"chrome shell\" in a way, that it runs the user\\'s app in an iframe.\\nDevTools then communicate with the user\\'s app via message passing.\\n\\n### Release builds\\n\\nYou can build the release version of Angular DevTools for either Chrome or Firefox with:\\n\\n```shell\\nyarn devtools:build:chrome\\nyarn devtools:build:firefox\\n```\\n\\nEither way, the built extension will be at `dist/bin/devtools/projects/shell-browser/src/prodapp`.\\n\\n#### Installation\\n\\nFor Chrome, you can install the extension from `dist/bin/devtools/projects/shell-browser/src/prodapp` by following the\\nguide from [here](https://developer.chrome.com/docs/extensions/get-started/tutorial/hello-world#load-unpacked).\\n\\nFor Firefox, to load the extension, you can go to the about:debugging page, click the \"This Firefox\" option and then\\nclick the Load Temporary Add-on button. You\\'ll have to select the manifest file in\\n`dist/bin/devtools/projects/shell-browser/src/prodapp` directly.\\n\\n', \"### *`public-api/`*\\n\\nThis directory contains all of the public api goldens for our npm packages we publish\\nto NPM.  These are tested on all PRs and commits as part of our bazel tests.\\n\\nTo check or update the public api goldens, run one of the following commands:\\n\\n```bash\\nyarn public-api:check\\nyarn public-api:update\\n```\\n\\n### *`packages-circular-deps.json`*\\n\\nThis golden file contains a list of all circular dependencies in the project. As part of the\\nlint CI job we compare the current circular dependencies against this golden to ensure that\\nwe don't add more cycles. If cycles have been fixed, this file is also updated so that we can\\nslowly burn down the number of cycles in the project.\\n\\nTo check or update the golden, run the following commands:\\n\\n```bash\\nyarn ts-circular-deps:check\\nyarn ts-circular-deps:approve\\n```\\n\", '# Integration tests for Angular\\n\\nThis directory contains end-to-end tests for Angular. Each directory is a self-contained application\\nthat exactly mimics how a user might expect Angular to work, so they allow high-fidelity\\nreproductions of real-world issues.\\n\\nFor this to work, we first build the Angular distribution via `yarn build`, then\\ninstall the distribution into each app.\\n\\nTo test Angular CLI applications, we use the `cli-hello-world-*` integration tests.\\nWhen a significant change is released in the CLI, the applications should be updated with\\n`ng update`:\\n\\n```bash\\n$ cd integration/cli-hello-world[-*]\\n$ yarn install\\n$ yarn ng update @angular/cli @angular-devkit/build-angular\\n$ yarn build\\n$ yarn test\\n```\\n\\nAfterwards the `@angular/cli` and `@angular-devkit/build-angular` should be reverted to the `file:../` urls\\nand the main `package.json` should be updated with the new versions.\\n\\n## Render3 tests\\n\\nThe directory `cli-hello-world-ivy-compat` contains a test for render3 used with the angular cli.\\n\\nThe `cli-hello-world-ivy-minimal` contains a minimal ivy app that is meant to mimic the bazel\\nequivalent in `packages/core/test/bundling/hello_world`, and should be kept similar.\\n\\n## Writing an integration test\\n\\nThe API for each test is:\\n\\n- Each sub-directory here is an integration test\\n- Each test should have a `package.json` file\\n- The test runner will run `yarn` and `yarn test` on the package\\n\\nThis means that the test should be started by test script, like\\n```\\n\"scripts\": {\"test\": \"runProgramA && assertResultIsGood\"}\\n```\\n\\nNote that the `package.json` file uses a special `file:../../dist` scheme to reference the Angular\\npackages, so that the locally-built Angular is installed into the test app.\\n\\nAlso, beware of floating (non-locked) dependencies. If in doubt, you can install the package\\ndirectly from `file:../../node_modules`.\\n\\n> WARNING\\n>\\n> Always ensure that `yarn.lock` files are up-to-date with the corresponding `package.json` files\\n> (wrt the non-local dependencies - i.e. dependencies whose versions do not start with `file:`).\\n>\\n> You can update a `yarn.lock` file by running `yarn install` in the project subdirectory.\\n\\n\\n## Running integration tests\\n\\n```\\n$ ./integration/run_tests.sh\\n```\\n\\nThe test runner will first re-build any stale npm packages, then `cd` into each subdirectory to\\nexecute the test.\\n\\n## Running integration tests under Bazel\\n\\nThe PR https://github.com/angular/angular/pull/33927 added the ability to run integration tests with Bazel. These tests can be resource intensive so it is recommended to limit the number of concurrent test jobs with the `--local_test_jobs` bazel flag.\\n\\nLocally, if Bazel uses all of your cores to run the maximum number of integration tests in parallel then this can lead to test timeouts and flakes and freeze up your machine while these tests are running. You can limit the number of concurrent local integration tests that run with:\\n\\n```\\nyarn bazel test --local_test_jobs=<N> //integration/...\\n```\\n\\nSet a reasonable `local_test_jobs` limit for your local machine to prevent full cpu utilization during local development test runs.\\n\\nTo avoid having to specify this command line flag, you may want to include it in your `.bazelrc.user` file:\\n\\n```\\ntest --local_test_jobs=<N>\\n```\\n\\nThe downside of this is that this will apply to all tests and not just the resource intensive integration tests.\\n\\n### Bazel-in-bazel integration tests\\n\\nTwo of the integration tests that run Bazel-in-Bazel are particularly resource intensive and are tagged \"manual\" and \"exclusive\". To run these tests use,\\n\\n```\\nyarn bazel test //integration/bazel:test\\nyarn bazel test //integration/cli-hello-world-ivy-minimal:test\\n```\\n\\n## Adding a new integration test\\n\\nWhen adding a new integration test, follow the steps below to add a bazel test target for the new test.\\n\\n1. Add a build file using the `ng_integration_test` rule from `//integration:index.bzl`.\\n2. If test requires ports and does not support ethereal ports then make sure the port is unique and add it to the \"manually configured ports\" section to document which port it is using\\n3. Add at least the following two entries `.bazelignore` (as they may contain BUILD files)\\n   1. `integration/new_test/node_modules`\\n   2. `integration/new_test/.yarn_local_cache`\\n4. Add any other untracked folders to `.bazelignore` that may contain `BUILD` files\\n5. If there are BUILD files in the integration test folder (except for the top-level one defining the test), add those folders to the `--deleted_packages` in the `.bazelrc`. An example is the `bazel_ngtsc_plugin` test within `//integration/bazel_workspace_tests`.\\n\\n## Manually configured ports\\n\\nSome integration ports must be managed manually to be unique and in other\\ncases the tests are able to select a random free port.\\n\\nWhere `ng e2e` is used we pass `ng e2e --port 0` which prompts the cli\\nto select a random free port for the e2e test. The protractor.conf is\\nautomatically updated to use this port.\\n\\nKarma automatically finds a free port so no effort is needed there.\\n\\nThe manually configured ports are as follows:\\n\\n| TEST | PORT | CONFIGURATION |\\n| ---------------------------- | ---------------- | -------------------------------------- |\\n| dynamic-compiler             |      4201        | /e2e/browser.config.json: \"port\": 4201 |\\n| ng_elements                  |      4205        | /e2e/browser.config.json: \"port\": 4205 |\\n| platform-server              |      4206        | /src/server.ts: app.listen(4206,...    |\\n\\n**Note**: This will become obsolete soon once we start running integration tests with RBE and within a sandbox environment.\\n\\n## Browser tests\\n\\nFor integration tests we use the Bazel-managed versions of `chromium`. For both Karma and Protractor tests we set a number of browser testing flags. To avoid duplication, they will be listed and explained here and the code will reference this file for more information.\\n\\n### No Sandbox: --no-sandbox\\n\\nThe sandbox needs to be disabled with the `--no-sandbox` flag for both Karma and Protractor tests, because it causes Chrome to crash on some environments.\\n\\nSee: https://chromedriver.chromium.org/help/chrome-doesn-t-start\\nSee: https://github.com/puppeteer/puppeteer/blob/v1.0.0/docs/troubleshooting.md#chrome-headless-fails-due-to-sandbox-issues\\n\\n### Headless: --headless\\n\\nSo that browsers are not popping up and tearing down when running these tests we run Chrome in headless mode. The `--headless` flag puts Chrome in headless mode and a number of other flags are recommended in this mode as well:\\n\\n* `--headless`\\n* `--disable-gpu`\\n* `--disable-dev-shm-usage`\\n* `--hide-scrollbars`\\n* `--mute-audio`\\n\\nThese come from the flags that puppeteer passes to chrome when it launches it in headless mode: https://github.com/puppeteer/puppeteer/blob/18f2ecdffdfc70e891750b570bfe8bea5b5ca8c2/lib/Launcher.js#L91\\n\\nAnd from the flags that the Karma `ChromeHeadless` browser passes to Chrome: https://github.com/karma-runner/karma-chrome-launcher/blob/5f70a76de87ecbb57f3f3cb556aa6a2a1a4f643f/index.js#L171\\n\\n#### Disable shared memory space: --disable-dev-shm-usage\\n\\nThe `--disable-dev-shm-usage` flag disables the usage of `/dev/shm` because it causes Chrome to crash on some environments.\\n\\nOn CircleCI, the puppeteer provisioned Chrome crashes with `CI we get Root cause: org.openqa.selenium.WebDriverException: unknown error: DevToolsActivePort file doesn\\'t exist which resolves` without this flag.\\n\\nSee: https://github.com/puppeteer/puppeteer/blob/v1.0.0/docs/troubleshooting.md#tips\\nSee: https://stackoverflow.com/questions/50642308/webdriverexception-unknown-error-devtoolsactiveport-file-doesnt-exist-while-t\\n\\n## Debugging Size Regressions\\n\\nIf size regression occurs, one way to debug is to get a build which shows the code before and after. Here are the steps to do that.\\n\\n1. Check out both the `main` branch as well as your change (let\\'s refer to it as `change` branch) into two different working locations. (A suggested way to do this is using `git worktree`.)\\n2. In both `main` and `change` locations update the failing tests `package.json` with `NG_BUILD_DEBUG_OPTIMIZE=minify` environment variable so that the resulting build would contain a human readable but optimized output. As an example:\\n   - Open `integration/cli-hello-world/package.json` and prefix `NG_BUILD_DEBUG_OPTIMIZE=minify` into the `build` rule. Resulting in something like: `\"build\": \"NG_BUILD_DEBUG_OPTIMIZE=minify ng build --prod\",`\\n   - Run `bazel test //integration/cli-hello-world:test --test_output=streamed --cache_test_results=no` to run the test.\\n   - Open the test temporary directory as printed out by Bazel.\\n   - Diff the `main` vs `change` to see the differences. `myDiffTool change/integration/cli-hello-world/dist/main-es2015.*.js main/integration/cli-hello-world/dist/main-es2015.*.js`\\n   - The above should give you a better understanding as to what has changed and what is causing the regression.\\n', 'Angular\\n=======\\n\\nThe sources for this package are in the main [Angular](https://github.com/angular/angular) repo. Please file issues and pull requests against that repo.\\n\\nUsage information and reference details can be found in [Angular documentation](https://angular.io/docs).\\n\\nLicense: MIT\\n', '# third_party vendored sources in Angular\\n\\n## TL;DR: don\\'t copy sources into this repo\\n\\nAll sources in this repo should be authored from scratch by the committer.\\nDon\\'t copy sources you\\'ve found in any other location.\\n\\n## What if I have a good reason?\\n\\nWe do \"vendor in\" some sources, in cases where we do not want our users to have a transitive dependency.\\nFor example, to make testing more reliable, we copy a font into our repo.\\nThat allows our integration tests to run without dynamically requesting that font.\\n\\nFollow these guidelines for adding sources under `third_party`:\\n\\n1. Only vendor sources with compatible licenses. Apache 2.0 and MIT are good. Any other licenses, check with your team lead so we can verify our ability to comply with the license.\\n1. Preserve the license for code. The best thing to do is copy the entire LICENSE file along with the sources.\\n1. Indicate where the sources came from. Our convention is to create a directory based on the URL where the sources were fetched. Add version number or if missing, the retrieval date, as a comment in the build file just above the license() call. Example: https://github.com/angular/angular/blob/master/third_party/fonts.google.com/open-sans/BUILD.bazel\\n1. Avoid changing the files you fetched. If you make any changes to the sources, first commit the original, then in a separate commit, make your edits. include another metadata file listing your changes, like https://github.com/bazelbuild/rules_nodejs/blob/master/third_party/github.com/source-map-support/LOCAL_MODS.md\\n1. Any bundle or distribution which includes this code needs to propagate the LICENSE file or content. Talk to your TL to make sure this is done correctly.\\n\\n## Under Bazel\\n\\nThis directory is treated specially by Bazel.\\n\\nAll BUILD.bazel files under `third_party` are required to have a `licenses` statement.\\nSee https://docs.bazel.build/versions/master/be/functions.html#licenses\\n\\nNote that we don\\'t yet have a way to enumerate the licenses and include them in our distribution.\\nFollow https://github.com/bazelbuild/bazel/issues/188\\n'], 'install.md': [], 'package.json': []}\n"
          ]
        }
      ],
      "source": [
        "load_dotenv()\n",
        "def retrieve_files(repo_urls, access_token):\n",
        "    file_names = ['README.md', 'install.md', 'package.json']\n",
        "    branches = ['main', 'master', 'develop']\n",
        "    files_content = {file_name: [] for file_name in file_names}\n",
        "\n",
        "    headers = {\n",
        "        'Authorization': f'token {os.getenv(\"GITHUB_TOKEN\")}'\n",
        "    }\n",
        "\n",
        "    for url in repo_urls:\n",
        "        if url.endswith('.git'):\n",
        "            trimmed_url = url[:-4]\n",
        "        else:\n",
        "            trimmed_url = url\n",
        "\n",
        "        for branch in branches:\n",
        "            try:\n",
        "                # Get the root directory contents for the branch\n",
        "                directories_url = f\"https://api.github.com/repos/{trimmed_url.split('/')[-2]}/{trimmed_url.split('/')[-1]}/contents/\"\n",
        "                response = requests.get(directories_url, params={'ref': branch}, headers=headers)\n",
        "                if response.status_code == 200:\n",
        "                    contents = response.json()\n",
        "\n",
        "                    # Iterate over each item in the root directory\n",
        "                    for item in contents:\n",
        "                        if item['type'] == 'dir':\n",
        "                            # If item is a directory, get its contents\n",
        "                            directory_url = item['url']\n",
        "                            directory_contents_response = requests.get(directory_url, headers=headers)\n",
        "                            if directory_contents_response.status_code == 200:\n",
        "                                directory_contents = directory_contents_response.json()\n",
        "\n",
        "                                # Iterate over files in the directory\n",
        "                                for file_item in directory_contents:\n",
        "                                    if file_item['type'] == 'file' and file_item['name'] in file_names:\n",
        "                                        file_url = f\"{trimmed_url.rstrip('/')}/raw/{branch}/{item['path']}/{file_item['name']}\"\n",
        "                                        try:\n",
        "                                            file_response = requests.get(file_url, headers=headers)\n",
        "                                            if file_response.status_code == 200:\n",
        "                                                files_content[file_item['name']].append(file_response.text)\n",
        "                                                print(f\"Successfully retrieved {file_item['name']} from {file_url}\")\n",
        "                                            else:\n",
        "                                                print(f\"Failed to retrieve {file_item['name']} from {file_url}. Status code: {file_response.status_code}\")\n",
        "                                        except requests.exceptions.RequestException as e:\n",
        "                                            print(f\"Error while trying to get {file_item['name']} from {file_url}: {e}\")\n",
        "                else:\n",
        "                    print(f\"Failed to retrieve directory contents from {directories_url}. Status code: {response.status_code}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error while processing repository {url}: {e}\")\n",
        "\n",
        "    return files_content\n",
        "\n",
        "# Example usage\n",
        "repo_urls = [\n",
        "    \"https://github.com/angular/angular.git\"\n",
        "]\n",
        "access_token = 'your_personal_access_token'  # Replace with your actual personal access token\n",
        "files_content = retrieve_files(repo_urls, access_token)\n",
        "print(files_content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqNtexJlrsAC"
      },
      "source": [
        "OpenAI API for getting repositories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6JLbTX8SrvO0"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "client = AzureOpenAI(\n",
        "    api_key = os.getenv(\"AZURE_OPENAI_KEY\"),\n",
        "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    api_version=\"2024-02-15-preview\" \n",
        ")\n",
        "def generate_github_repos(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    system_prompt = \"You are an AI assistant that suggests relevant GitHub repositories based on a project description.\"\n",
        "    user_prompt = f\"Suggest GitHub repositories for a project that involves the following technologies: {prompt}. Provide only the URLs of the repositories.\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    suggested_repos = response.choices[0].message.content.strip()\n",
        "    repo_urls = re.findall(r'(https?://github\\.com/[^\\s]+)', suggested_repos)\n",
        "    return repo_urls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OnKaxF7X4fe"
      },
      "source": [
        "Analyze and pre-process the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rw0PzSofrwpL"
      },
      "outputs": [],
      "source": [
        "def parse_readme(content):\n",
        "    sections = {}\n",
        "    current_section = None\n",
        "    lines = content.split('\\n')\n",
        "\n",
        "    for line in lines:\n",
        "        header_match = re.match(r'^(#+)\\s+(.*)', line)\n",
        "        if header_match:\n",
        "            level = len(header_match.group(1))\n",
        "            section_name = header_match.group(2).strip()\n",
        "            current_section = section_name\n",
        "            sections[current_section] = []\n",
        "        elif current_section:\n",
        "            sections[current_section].append(line)\n",
        "\n",
        "    for section in sections:\n",
        "        sections[section] = \"\\n\".join(sections[section])\n",
        "\n",
        "    return sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bbzs3gu2tHcG"
      },
      "outputs": [],
      "source": [
        "def parse_package_json(content):\n",
        "    try:\n",
        "        package_data = json.loads(content)\n",
        "        return {\n",
        "            \"dependencies\": package_data.get(\"dependencies\", {}),\n",
        "            \"devDependencies\": package_data.get(\"devDependencies\", {}),\n",
        "            \"scripts\": package_data.get(\"scripts\", {})\n",
        "        }\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error parsing package.json: {e}\")\n",
        "        return {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qvL53TGvtLjH"
      },
      "outputs": [],
      "source": [
        "def collect_context(files_content):\n",
        "    context = {}\n",
        "\n",
        "    for file_name, contents in files_content.items():\n",
        "        if file_name == 'README.md':\n",
        "            for content in contents:\n",
        "                context[file_name] = parse_readme(content)\n",
        "        elif file_name == 'package.json':\n",
        "            for content in contents:\n",
        "                context[file_name] = parse_package_json(content)\n",
        "\n",
        "    return context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b7IEDS64vbc"
      },
      "source": [
        "Validation of output, this is just for us to see how is data being processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c61ngjPXyyeD",
        "outputId": "b6a3702a-e500-46f8-8a9c-b02284d50094"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'context' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#context is underlined beacuse it's defined below, in main code section, but that doesn't matter since this is jupyter notebook\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpackage.json\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcontext\u001b[49m:\n\u001b[0;32m      3\u001b[0m     package_info \u001b[38;5;241m=\u001b[39m context[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpackage.json\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m     dependencies \u001b[38;5;241m=\u001b[39m package_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdependencies\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n",
            "\u001b[1;31mNameError\u001b[0m: name 'context' is not defined"
          ]
        }
      ],
      "source": [
        "#context is underlined beacuse it's defined below, in main code section, but that doesn't matter since this is jupyter notebook\n",
        "if 'package.json' in context:\n",
        "    package_info = context['package.json']\n",
        "    dependencies = package_info.get('dependencies', {})\n",
        "    dev_dependencies = package_info.get('devDependencies', {})\n",
        "    scripts = package_info.get('scripts', {})\n",
        "\n",
        "    print(\"Dependencies:\", dependencies)\n",
        "    print(\"Dev Dependencies:\", dev_dependencies)\n",
        "    print(\"Scripts:\", scripts)\n",
        "else:\n",
        "    print(\"No 'package.json' found in context.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c4jHad3y__n",
        "outputId": "4979bfe1-4076-4787-b748-d060c648924f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'context' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#context is underlined beacuse it's defined below, in main code section, but that doesn't matter since this is jupyter notebook\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREADME.md\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcontext\u001b[49m:\n\u001b[0;32m      3\u001b[0m     readme_info \u001b[38;5;241m=\u001b[39m context[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREADME.md\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m section_name, section_content \u001b[38;5;129;01min\u001b[39;00m readme_info\u001b[38;5;241m.\u001b[39mitems():\n",
            "\u001b[1;31mNameError\u001b[0m: name 'context' is not defined"
          ]
        }
      ],
      "source": [
        "#context is underlined beacuse it's defined below, in main code section, but that doesn't matter since this is jupyter notebook\n",
        "if 'README.md' in context:\n",
        "    readme_info = context['README.md']\n",
        "\n",
        "    for section_name, section_content in readme_info.items():\n",
        "        print(f\"Section: {section_name}\")\n",
        "        print(section_content)\n",
        "        print()\n",
        "else:\n",
        "    print(\"No 'README.md' found in context.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8sQjtEG1WSh"
      },
      "source": [
        "Generate JSON file for Dev Container with OpenAI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "R15es83F1cLG"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "client = AzureOpenAI(\n",
        "    api_key = os.getenv(\"AZURE_OPENAI_KEY\"),\n",
        "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    api_version=\"2024-02-15-preview\"  \n",
        ")\n",
        "\n",
        "def generate_dev_container_json(context, model=\"gpt-3.5-turbo\"):\n",
        "    system_prompt = \"You are an AI assistant that creates JSON file for dev container.\\n\\n\"\n",
        "    user_prompt = f\"Generate JSON configuration for dev container based on the context provided: {context}\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(\"Raw API Response:\")\n",
        "    print(response)\n",
        "\n",
        "    if 'data' in response:\n",
        "        for message in response['data']:\n",
        "            if message['role'] == 'assistant':\n",
        "                generated_json = message['content']\n",
        "                try:\n",
        "                    parsed_json = json.loads(generated_json)\n",
        "                    print(\"Generated Dev Container JSON Configuration:\")\n",
        "                    print(json.dumps(parsed_json, indent=4))\n",
        "                    return parsed_json\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Error decoding JSON: {e}\")\n",
        "                    return None\n",
        "            else:\n",
        "                print(f\"Role '{message['role']}' not recognized.\")\n",
        "                return None\n",
        "    else:\n",
        "        print(\"No 'data' key found in API response.\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TUo797zZ2tN"
      },
      "source": [
        "Main code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJf_6snmZ56b",
        "outputId": "58622757-38fc-42b2-ab41-201b1e7fe854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Did not find README.md\n",
            "Did not find install.md\n",
            "Did not find package.json\n"
          ]
        },
        {
          "ename": "NotFoundError",
          "evalue": "Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[35], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m   files\u001b[38;5;241m=\u001b[39mretrieve_files(repo)\n\u001b[0;32m      8\u001b[0m context \u001b[38;5;241m=\u001b[39m collect_context(files)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mgenerate_dev_container_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[10], line 12\u001b[0m, in \u001b[0;36mgenerate_dev_container_json\u001b[1;34m(context, model)\u001b[0m\n\u001b[0;32m      9\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an AI assistant that creates JSON file for dev container.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m user_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerate JSON configuration for dev container based on the context provided: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaw API Response:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
            "File \u001b[1;32mc:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\resources\\chat\\completions.py:643\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    641\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    642\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:1250\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1238\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1245\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1246\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1247\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1248\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1249\u001b[0m     )\n\u001b[1;32m-> 1250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[1;32mc:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:931\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    924\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    929\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    930\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 931\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Mate\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:1030\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1027\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1029\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1030\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1033\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1034\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1038\u001b[0m )\n",
            "\u001b[1;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}"
          ]
        }
      ],
      "source": [
        "if flag == False:\n",
        "  repos=generate_github_repos(prompt)\n",
        "  print(repos)\n",
        "  files=retrieve_files(repos)\n",
        "else:\n",
        "  repo=[prompt]\n",
        "  files=retrieve_files(repo)\n",
        "context = collect_context(files)\n",
        "generate_dev_container_json(context)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
